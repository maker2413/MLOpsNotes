#+TITLE: Chapter 1
#+PROPERTY: header-args:python :session loan
#+PROPERTY: header-args:python+ :tangle loan.py
#+PROPERTY: header-args:python+ :results output
#+PROPERTY: header-args:python+ :shebang "#!/usr/bin/env python"

#+BEGIN_SRC elisp :exports none :results none
  ;; This will make org-babel use the .venv directory in this repo
  (setq org-babel-python-command (concat
                                  (file-name-directory (or load-file-name (buffer-file-name)))
                                  ".venv/bin/python"))
#+END_SRC

In this section we will learn how to package trained ML models. To begin with
pretend we are working for a company that wants to automate the loan eligibility
detection based on the customer details provided in an online application form.

We need to classify each row as - whether a loan would be approved or not. We
should begin by exploring our dataset.

Let's begin with importing a couple of python libraries that will be required to
interact with the sample data we have been given:
#+begin_src python :results none
  import numpy as np
  import pandas as pd
  from sklearn.impute import SimpleImputer
  from sklearn.preprocessing import LabelEncoder,MinMaxScaler
#+end_src

In this directory we have a =train.csv= file that contains data to train our
model and a =test.csv= file that contains data to test our model. Now let's open
our training and test csv files:
#+begin_src python :results none
  raw_train = pd.read_csv("train.csv")
  raw_test = pd.read_csv("test.csv")
#+end_src

We can then print the beginning of our training file to prove that we have
opened it properly:
#+name: printhead
#+begin_src python :exports both :tangle no :results value
  raw_train.head()
#+end_src

#+RESULTS: printhead
:     Loan_ID Gender Married Dependents  ... Loan_Amount_Term Credit_History  Property_Area  Loan_Status
: 0  LP001002   Male      No          0  ...            360.0            1.0          Urban            Y
: 1  LP001003   Male     Yes          1  ...            360.0            1.0          Rural            N
: 2  LP001005   Male     Yes          0  ...            360.0            1.0          Urban            Y
: 3  LP001006   Male     Yes          0  ...            360.0            1.0          Urban            Y
: 4  LP001008   Male      No          0  ...            360.0            1.0          Urban            Y
: 
: [5 rows x 13 columns]

Mind you this is just a small sample of our dataset, however we can see that we
have an ID value in the first column of this output. We can use the following to
see how many unique IDs we have this dataset:
#+begin_src python :exports both :tangle no :results value
  raw_train.nunique()
#+end_src

#+RESULTS:
#+begin_example
Loan_ID              614
Gender                 2
Married                2
Dependents             4
Education              2
Self_Employed          2
ApplicantIncome      505
CoapplicantIncome    287
LoanAmount           203
Loan_Amount_Term      10
Credit_History         2
Property_Area          3
Loan_Status            2
dtype: int64
#+end_example

We can also see how many rows and columns we have in this dataset with the
following:
#+name: shape
#+begin_src python :exports both :tangle no :results value
  raw_train.shape
#+end_src

We can see that we have 13 columns and 614 rows:
#+RESULTS: shape
| 614 | 13 |

Now to be honest, the ID column isn't going to be useful for the actual training
of our model so we can just drop that column. Before we do that though let's
store a copy of our existing variable in a new variable so that we still have
the original variable to play with without reopening the file:
#+begin_src python :results none
  train_df = raw_train.copy()
  test_df = raw_test.copy()
#+end_src

Let's confirm all of our data is present in our new variable:
#+begin_src python :exports both :results output
  train_df.info()
#+end_src

#+RESULTS:
#+begin_example
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 614 entries, 0 to 613
Data columns (total 13 columns):
 #   Column             Non-Null Count  Dtype  
---  ------             --------------  -----  
 0   Loan_ID            614 non-null    object 
 1   Gender             601 non-null    object 
 2   Married            611 non-null    object 
 3   Dependents         599 non-null    object 
 4   Education          614 non-null    object 
 5   Self_Employed      582 non-null    object 
 6   ApplicantIncome    614 non-null    int64  
 7   CoapplicantIncome  614 non-null    float64
 8   LoanAmount         592 non-null    float64
 9   Loan_Amount_Term   600 non-null    float64
 10  Credit_History     564 non-null    float64
 11  Property_Area      614 non-null    object 
 12  Loan_Status        614 non-null    object 
dtypes: float64(4), int64(1), object(8)
memory usage: 62.5+ KB
#+end_example

We can also see from the above output that although we have 614 rows in our
newly created training data frame variable not all of our columns have 614 rows
of data. That is just a simple observation we can make about the dataset we were
given. Let's now check to see what the contents of our test data frame are:
#+begin_src python :exports both :results output
  test_df.info()
#+end_src

#+RESULTS:
#+begin_example
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 362 entries, 0 to 361
Data columns (total 12 columns):
 #   Column             Non-Null Count  Dtype  
---  ------             --------------  -----  
 0   Loan_ID            362 non-null    object 
 1   Gender             351 non-null    object 
 2   Married            362 non-null    object 
 3   Dependents         353 non-null    object 
 4   Education          362 non-null    object 
 5   Self_Employed      339 non-null    object 
 6   ApplicantIncome    362 non-null    int64  
 7   CoapplicantIncome  362 non-null    int64  
 8   LoanAmount         362 non-null    int64  
 9   Loan_Amount_Term   356 non-null    float64
 10  Credit_History     333 non-null    float64
 11  Property_Area      362 non-null    object 
dtypes: float64(2), int64(3), object(7)
memory usage: 34.1+ KB
#+end_example

We can see from this that our test data frame only has 12 columns and is in fact
missing the =Loan_Status= column so we will only be able to use this test data
for generating the prediction and we will not be able to use our test data for
preforming the evaluation of our model.
